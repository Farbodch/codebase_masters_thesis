{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\text{The Ishigami Function}$\n",
    "## Scalar-Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_set = [100,1000,10000,100000]\n",
    "num_of_experiments_per_N = 50\n",
    "model_save_directory = 'data/ishigami/pick_freeze'\n",
    "model_save_name = f'N_set_{N_set}__numOfExperiments_{num_of_experiments_per_N}'.replace(\"[\",\"\").replace(\"]\",\"\").replace(\",\",\"_\").replace(\" \",\"\")\n",
    "print(model_save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ishigami = model(model_type=\"ishigami\", vectSize=3, model_save_directory=model_save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load an existing model (and data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ishigami = load_model(load_dir=f'{model_save_directory}/{model_save_name}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the Pick-Freeze estimation for the ishigami function's main-effect Sobol' indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sobols(model=ishigami, N_set=N_set, itersPerN=num_of_experiments_per_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model and data if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ishigami.save_model(file_name=model_save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.plot(model=ishigami,\n",
    "            multi_experiment=True,\n",
    "            withOutliers=False,\n",
    "            withTrend=True,\n",
    "            no_title=True,\n",
    "            not_differences=False,\n",
    "            only_singulars=True,\n",
    "            base_fontsize=20,\n",
    "            save_fig=True,\n",
    "            save_directory='figs/ishigami/pick_freeze/scalar',\n",
    "            fig_name=f'ishigami_pickFreeze_convergence_{model_save_name}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\text{The Ishigami Function}$\n",
    "## Vectorized-Set-Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import numeric_models as nm\n",
    "from utils import plotter, solvers\n",
    "from utils.other_utils import gen_uniform_1d_mesh_from_interval_and_resolution as genUniMesh\n",
    "from utils.other_utils import load_model, save_model, getSingletonIndexAsInt\n",
    "from glob import glob, escape\n",
    "import time\n",
    "import numpy as np\n",
    "from os import makedirs\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating aggr' sobols by calculating weights individually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interval_domain = [-np.pi, -2.0]\n",
    "interval_domain = [-np.pi, np.pi]\n",
    "interval_mesh_resolution = 8\n",
    "ishigami_indicator_constraint_val = 3\n",
    "x3_as_mesh = genUniMesh(domain=interval_domain, mesh_resolution=interval_mesh_resolution)\n",
    "expNum_set = [1000]\n",
    "N_set = [1000]\n",
    "N_min = np.min(N_set)\n",
    "N_max = np.max(N_set)\n",
    "save_dir = 'data/ishigami/indicator/scalar/mesh_x3_'\n",
    "save_dir += f'{list(np.round(interval_domain, 2))}'.replace(\"np.float64(\", \"\").replace(\")\", \"\").replace('.','_').replace(' ', '').replace('-','neg').replace('[','<').replace(']','>')\n",
    "save_dir += f'_h_{interval_mesh_resolution}_constraint_{ishigami_indicator_constraint_val}'\n",
    "print(save_dir)\n",
    "makedirs(save_dir, exist_ok=True)\n",
    "ishi_models_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_3 in x3_as_mesh:\n",
    "    t0 = time.time()\n",
    "    ishigami = nm.model(model_type='ishigami', vectSize=2)  \n",
    "    ishigami.specifyX3 = True\n",
    "    ishigami.x_3 = x_3\n",
    "    ishigami.ishigami_indicator = True\n",
    "    ishigami.constraintVal = ishigami_indicator_constraint_val\n",
    "    for _ in range(expNum_set[0]):\n",
    "        solvers.run_sobols(model=ishigami, N_set=N_set)\n",
    "    ishi_models_list.append(ishigami)\n",
    "    save_name = f\"x3_{np.round(x_3,2)}\".replace('.', '_').replace('-', 'neg')\n",
    "    save_model(model=ishigami, save_dir=save_dir, save_name=save_name)\n",
    "    t1 = time.time()\n",
    "    print(f\"Done for x_3: {x_3:0.2f} | T: {t1-t0:0.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data (if not run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ishi_models_list = []\n",
    "files = glob(f\"{save_dir}/*.pkl\")\n",
    "\n",
    "for file in files:\n",
    "    print(file)\n",
    "    ishi_models_list.append(load_model(load_dir=file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate $S^{\\text{clos},Y}_A$ (Aggregate sobol indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_hat_list_all_exps = []\n",
    "for experim_i_key in range(expNum_set[0]):\n",
    "    V_hat_list_all_exps.append([np.mean([ishi_models_list[x3_idx].exprimentDataDict[0][experim_i_key]['indiv_output_variance'][f\"{N_set[-1]}\"]]) for x3_idx in range(len(ishi_models_list))])\n",
    "V_hat_list_all_exps = np.array(V_hat_list_all_exps)\n",
    "sum_all_v_hat_all_exps = np.sum(V_hat_list_all_exps,axis=1)\n",
    "c_j_list_all_exps = V_hat_list_all_exps / sum_all_v_hat_all_exps[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_order_indices = ['01', '10']\n",
    "sobolVals_clos_aggr_adjusted = {k: [] for k in first_order_indices}\n",
    "num_of_experiments = len(ishi_models_list[0].exprimentDataDict[0])\n",
    "N_set = ishi_models_list[0].N_set       \n",
    "N_final = f\"{N_set[-1]}\" # can adjust so we can do for multiple N instead of just the N_final                              \n",
    "num_of_mesh_nodes = len(ishi_models_list)\n",
    "for sob_idx_str in first_order_indices:\n",
    "    # for each sample i, compute the weighted sum across models\n",
    "    for i in range(num_of_experiments):\n",
    "        weighted_sum = 0.0\n",
    "        for model_idx in range(num_of_mesh_nodes):\n",
    "            val = ishi_models_list[model_idx].exprimentDataDict[0][i]['sobolVals_clos'][N_final][sob_idx_str]\n",
    "            weighted_sum += val * c_j_list_all_exps[model_idx]\n",
    "        sobolVals_clos_aggr_adjusted[sob_idx_str].append(weighted_sum)\n",
    "values = np.array([np.asarray(sobolVals_clos_aggr_adjusted['01']).reshape(-1), np.asarray(sobolVals_clos_aggr_adjusted['10']).reshape(-1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot individually calculated Aggr Sobol' Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from os import path, makedirs\n",
    "import re\n",
    "\n",
    "def plot_indiv_calculated_S_aggr(values,\n",
    "                                N_set,\n",
    "                                base_fontsize=20,\n",
    "                                save_fig=False,\n",
    "                                save_directory='',\n",
    "                                fig_name=''):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 8), sharey=True)\n",
    "    plt.rcParams['font.family'] = 'STIXGeneral'\n",
    "    colors = [\"tomato\", \"royalblue\"]\n",
    "    base_fontsize = base_fontsize\n",
    "\n",
    "    for ax, val, color in zip(axes, values, colors):\n",
    "        box = ax.boxplot(val, patch_artist=True, showfliers=False)\n",
    "        ax.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "        for patch in box['boxes']:\n",
    "            patch.set_facecolor(color)\n",
    "            patch.set_edgecolor(\"black\")\n",
    "        for whisker in box['whiskers']:\n",
    "            whisker.set_color(color)\n",
    "        for cap in box['caps']:\n",
    "            cap.set_color(color)\n",
    "        for median in box['medians']:\n",
    "            median.set_color(\"black\")\n",
    "        ax.set_xticks(range(1, len(N_set) + 1))         \n",
    "        myXTicks = [rf\"$10^{int(np.log10(x))}$\" for x in N_set]\n",
    "        ax.set_xticklabels(myXTicks)\n",
    "        ax.tick_params(axis='x', labelsize=base_fontsize)\n",
    "        ax.tick_params(axis='y', labelsize=base_fontsize)\n",
    "        for label in ax.get_xticklabels():\n",
    "            label.set_fontname('STIXGeneral')\n",
    "\n",
    "    fig.supylabel(r\"$\\hat{S}^{aggr}_{A}$\", fontsize=(base_fontsize+2))\n",
    "    fig.supxlabel(r\"Number of Samples, $N$\", fontsize=(base_fontsize+2), y=0.02)\n",
    "    box_handles = [mpatches.Patch(color=c, label=rf\"$U_{i+1}$\") for i, c in enumerate(colors)]\n",
    "    if base_fontsize <= 11:\n",
    "        vert_space_add_to_legend = 0.02\n",
    "    else:\n",
    "        vert_space_add_to_legend = (base_fontsize-14)/100\n",
    "    fig.legend(handles=box_handles,\n",
    "                loc=\"upper center\",\n",
    "                ncol=len(colors) + 1,\n",
    "                bbox_to_anchor=(0.5, 1.00+vert_space_add_to_legend),\n",
    "                fontsize=(base_fontsize+1),\n",
    "                frameon=False) \n",
    "    fig.tight_layout(rect=[0.01, 0, 1, 0.97])\n",
    "    if save_fig:\n",
    "        if save_directory == '':\n",
    "            save_directory = model.figsave_directory\n",
    "        else:\n",
    "            if not path.exists(save_directory):\n",
    "                makedirs(save_directory)\n",
    "        if fig_name == '':\n",
    "            fig_name = 'ishigami_pickfreeze.pdf'\n",
    "        plt.savefig(f\"{save_directory}/{fig_name}\", dpi=900, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "interval=re.search(r\"<(.*?)>\", files[0]).group(1)\n",
    "save_directory = 'figs/ishigami/pick_freeze/mesh/scalar'\n",
    "fig_name = f'ishigami_scalared_mesh_h_{len(files)-1}_interval_{interval}_Nexp_{num_of_experiments}_Nset_{N_set}.pdf'.replace(',', '_').replace('[','').replace(']','').replace(' ', '')\n",
    "print(fig_name)\n",
    "plot_indiv_calculated_S_aggr(values=values, \n",
    "                            N_set=N_set, \n",
    "                            base_fontsize=20,\n",
    "                            save_fig=True,\n",
    "                            save_directory=save_directory,\n",
    "                            fig_name=fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Aggr Sobols' Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_axis_keys = list(sobolVals_clos_aggr_adjusted_.keys())\n",
    "y_axis_values = list(sobolVals_clos_aggr_adjusted_.values())\n",
    "x_tick_pos = np.arange(len(x_axis_keys))\n",
    "plt.scatter(x_tick_pos, y_axis_values, color=\"blue\", s=80)\n",
    "plt.xticks(x_tick_pos, x_axis_keys)\n",
    "plt.xlabel(\"Input indices\")\n",
    "plt.ylabel(r\"$S^{aggr}_A$\")\n",
    "interval_as_str = f'{list(np.round(interval_domain, 2))}'.replace(\"np.float64(\", \"\").replace(\")\", \"\")\n",
    "plt.title(r\"Aggr. Sobols for Ishigami on interval $x_3\\in$\" + f\"{interval_as_str}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Individual Sobols' Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in ishi_models_list:\n",
    "    plotter.plot(model=model,\n",
    "            multi_experiment=True,\n",
    "            withOutliers=False,\n",
    "            withTrend=False,\n",
    "            not_differences=True,\n",
    "            only_singulars=True,\n",
    "            save_fig=False)\n",
    "            # save_directory=f'kbsa/sobol_indicator_figs',\n",
    "            # fig_name=f'sobol_boxplots_x3_{x3}_N_[1e{int(np.log10(N_min))}:1e{int(np.log10(N_max))}]__indicator__NoOutliers__onlySingulars.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating aggr' sobols via trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import numeric_models as nm\n",
    "from utils import plotter, solvers\n",
    "from utils.other_utils import gen_uniform_1d_mesh_from_interval_and_resolution as genUniMesh\n",
    "from utils.other_utils import load_model, save_model, getSingletonIndexAsInt\n",
    "from glob import glob, escape\n",
    "import time\n",
    "import numpy as np\n",
    "from os import makedirs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_domain = [-np.pi, np.pi]\n",
    "interval_mesh_resolution = 8\n",
    "ishigami_indicator_constraint_val = 3\n",
    "expNum_set = [50]\n",
    "N_set = [100,1000,10000,100000]\n",
    "N_min = np.min(N_set)\n",
    "N_max = np.max(N_set)\n",
    "save_dir = 'data/ishigami/indicator/vector/'\n",
    "save_dir += f'{list(np.round(interval_domain,2))}_expNum_{expNum_set}_Nset_{N_set}'.replace(\"np.float64(\", \"\").replace(\")\", \"\").replace('.','_').replace(' ', '').replace('-','neg').replace('[','<').replace(']','>')\n",
    "save_dir += f'_h_{interval_mesh_resolution}_constraint_{ishigami_indicator_constraint_val}'\n",
    "makedirs(save_dir, exist_ok=True)\n",
    "ishi_vect_models_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "ishigami_vect = nm.model(model_type='ishigami_vect', vectSize=2)\n",
    "ishigami_vect.ishigami_indicator = True\n",
    "ishigami_vect.constraintVal = ishigami_indicator_constraint_val\n",
    "ishigami_vect.meshInterval = interval_mesh_resolution\n",
    "ishigami_vect.set_uniform_1D_mesh(interval=interval_domain)\n",
    "\n",
    "for _ in range(expNum_set[0]):\n",
    "    solvers.run_sobols(model=ishigami_vect, N_set=N_set, x_interval_of_interest=interval_domain)\n",
    "ishi_vect_models_list.append(ishigami_vect)\n",
    "save_name = \"ishigami_vect_model\"\n",
    "save_model(model=ishigami_vect, save_dir=save_dir, save_name=save_name)\n",
    "t1 = time.time()\n",
    "print(f\"Done | t: {t1-t0:0.3f} (s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from utils import plotter\n",
    "from utils.other_utils import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ishi_vect_models_list = []\n",
    "files = glob(\"data/ishigami/indicator/vector/**/*.pkl\")\n",
    "for file in files:\n",
    "    if 'Nset' not in file:\n",
    "        continue\n",
    "    if '100000' not in file:\n",
    "        continue\n",
    "    print(file)\n",
    "    ishi_vect_models_list.append(load_model(load_dir=file))\n",
    "ishi_vect_models_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ishi_vect_models_list[1].ishi_interval = [-np.pi, -1.0]\n",
    "ishi_vect_models_list[2].ishi_interval = [-np.pi, np.pi]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = 'figs/ishigami/pick_freeze/mesh/trace'\n",
    "for model in ishi_vect_models_list:\n",
    "    interval_domain = model.ishi_interval\n",
    "    interval_domain_trimmed = [round(x, 2) for x in interval_domain]\n",
    "    N_set = model.N_set\n",
    "    num_of_experiments = len(model.exprimentDataDict[str(interval_domain).replace(\" \", \"\")])\n",
    "    mesh_resolution = model.meshInterval\n",
    "    fig_name = f'ishigami_traced_mesh_h_{mesh_resolution}_interval_{interval_domain_trimmed}_Nexp_{num_of_experiments}_Nset_{N_set}'.replace(',', '_').replace('[','').replace(']','').replace(' ', '').replace('.','_').replace('-','neg') + '.pdf'\n",
    "    print(fig_name)\n",
    "    plotter.plot(model=model,\n",
    "                    N_set=N_set,\n",
    "                    plot_type='sobols',\n",
    "                    not_differences=True,\n",
    "                    only_singulars=True,\n",
    "                    interval_toggle=True,\n",
    "                    multi_experiment=True,\n",
    "                    which_interval=interval_domain, \n",
    "                    which_N=N_set[0],\n",
    "                    base_fontsize=20,# $$3vfdADFA,\n",
    "                    plot_which_sobols='closed_aggr',\n",
    "                    no_title=True,\n",
    "                    withTrend=True,\n",
    "                    save_fig=True,\n",
    "                    save_directory=save_directory,\n",
    "                    fig_name=fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\text{The 1D-Diffusion Problem}$\n",
    "## Scalar-Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import numeric_models as nm\n",
    "from utils import solvers\n",
    "import time\n",
    "import numpy as np\n",
    "from os import makedirs\n",
    "from sys import stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these indices represent the h+1 many spatial-mesh-node-indices. Eg, index 1 translates to spatial point x=1/(h+1), and 32 to x=32/(h+1)\n",
    "evaluate_at_x_idx_list = [1,32,64] \n",
    "interval_mesh_resolution = 128\n",
    "diffuFen_sobol_vect_len = interval_mesh_resolution+1\n",
    "P = 3\n",
    "mu = 1\n",
    "std = 5\n",
    "indicator_constraint_val = 0.135\n",
    "indicator_toggle = False\n",
    "expNum_set = [20]\n",
    "N_set = [100, 1000]\n",
    "\n",
    "N_min = np.min(N_set)\n",
    "N_max = np.max(N_set)\n",
    "if indicator_toggle:\n",
    "    save_dir = f'data/1d_diffusion/pick_freeze/indicator/scalar/h_{interval_mesh_resolution}_max_N_{N_set[-1]}/'\n",
    "else:\n",
    "    save_dir = f'data/1d_diffusion/pick_freeze/non-indicator/scalar/h_{interval_mesh_resolution}_max_N_{N_set[-1]}/'\n",
    "print(save_dir)\n",
    "makedirs(save_dir, exist_ok=True)\n",
    "diffuFen_models_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_idx in evaluate_at_x_idx_list:\n",
    "    save_name = f'1d_diffusion_xIdx_{x_idx}_xVal_{x_idx/129:.2f}_Nset_{N_set}'\n",
    "    save_name = save_name.replace(\"np.int64(\", \"\").replace(\"np.float64(\", \"\").replace(\")\", \"\").replace('.','_').replace(' ', '').replace('-','neg').replace('[','<').replace(']','>')\n",
    "    if indicator_toggle:\n",
    "        save_name += f'_sobVectLen_{diffuFen_sobol_vect_len}_h_{interval_mesh_resolution}_constraint_{indicator_constraint_val}'\n",
    "    else:\n",
    "        save_name += f'_sobVectLen_{diffuFen_sobol_vect_len}_h_{interval_mesh_resolution}'\n",
    "    \n",
    "\n",
    "    t0 = time.time()\n",
    "    diffusion_1d = nm.model(model_type='diffusion_1D_both',\n",
    "                            P=P,\n",
    "                            mean=mu,\n",
    "                            std=std,\n",
    "                            meshInterval=interval_mesh_resolution,\n",
    "                            indicator_toggle=indicator_toggle,\n",
    "                            indicator_constraint_val=indicator_constraint_val,\n",
    "                            FEM_projection=False,\n",
    "                            model_save_directory=save_dir,\n",
    "                            model_save_name=save_name)\n",
    "    t0_inner, t1_inner = 0, 0\n",
    "    t0_outer = time.time()\n",
    "    for curr_exp in range(expNum_set[0]):\n",
    "        if curr_exp != 0:\n",
    "            stdout.write(f'\\r{save_name} | time_prev_experiment_#{curr_exp}: {t1_inner-t0_inner:0.3f} (s). Time so far: {t1_inner-t0_outer:0.3f} (s)')\n",
    "            stdout.flush()\n",
    "        t0_inner = time.time()\n",
    "        solvers.run_sobols(model=diffusion_1d, N_set=N_set, scalarDiffuIdx=x_idx)\n",
    "        t1_inner = time.time()\n",
    "    diffuFen_models_list.append(diffusion_1d)\n",
    "    print('\\n')\n",
    "    diffusion_1d.save_my_model()\n",
    "    # save_model(model=diffusion_1d, save_dir=save_dir, save_name=save_name)\n",
    "    t1 = time.time()\n",
    "    print(f\" -> {x_idx/129} done! Total time: {t1-t0:0.3f} (s).\\n---------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from utils.other_utils import load_model\n",
    "\n",
    "diffuFen_models_list = []\n",
    "file_sup_dir = 'data/1d_diffusion/pick_freeze/non-indicator/scalar/h_128_max_N_1000'\n",
    "files = glob(f\"{file_sup_dir}/*.pkl\")\n",
    "for file in files:\n",
    "    print(file)\n",
    "    diffuFen_models_list.append(load_model(load_dir=file))\n",
    "diffuFen_models_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plotter\n",
    "import re\n",
    "for file in files:\n",
    "    model = load_model(load_dir=file)\n",
    "# for model in diffuFen_models_list:\n",
    "    file_name = file[len(file_sup_dir)+1:-4]\n",
    "    print(file_name)\n",
    "    which_index = list(model.exprimentDataDict.keys())[0]\n",
    "    plotter.plot(model=model,\n",
    "                N_set=model.N_set,\n",
    "                only_singulars=True,\n",
    "                withOutliers=False,\n",
    "                withTrend=False,\n",
    "                grid_toggle=True,\n",
    "                base_fontsize=22,\n",
    "                save_fig=True,\n",
    "                which_interval = None,\n",
    "                which_index = which_index,\n",
    "                save_directory='figs/1d_diffusion/vbsa/scalar',\n",
    "                fig_name=file_name)\n",
    "                # save_directory='figs/toy_2/pick_freeze/traced',\n",
    "                # fig_name=f'toy_2_convergence_{save_name}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\text{The 1D-Diffusion Problem}$\n",
    "## Vectorized-Set-Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import numeric_models as nm\n",
    "from utils import solvers\n",
    "import time\n",
    "import numpy as np\n",
    "from os import makedirs\n",
    "from sys import stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interval_domain_list = [[0.0,1.0],[0.3,0.7],[0.45,0.55],[0.6,1.0]]\n",
    "# interval_domain_list = [[0.0,1.0],[0.45,0.55]]\n",
    "interval_domain_list = [[0.0,0.4], [0.6,1.0]]\n",
    "interval_mesh_resolution = 1024\n",
    "\n",
    "#this is set equal to mesh_interval when model is initiated. One can change it to maintain a specific resolution to sample equally from\n",
    "#if the projectOutputToCG option is chosen\n",
    "projectOutputToCG = False\n",
    "diffuFen_sobol_vect_len = interval_mesh_resolution+1\n",
    "P = 3\n",
    "mu = 1\n",
    "std = 5\n",
    "indicator_constraint_val = 0.135\n",
    "indicator_toggle = True\n",
    "\n",
    "expNum_set = [20]\n",
    "N_set = [100,1000,10000]\n",
    "\n",
    "N_min = np.min(N_set)\n",
    "N_max = np.max(N_set)\n",
    "save_dir = f'data/1d_diffusion/pick_freeze/indicator/vector/h_{interval_mesh_resolution}_max_N_{N_set[-1]}/'\n",
    "if projectOutputToCG:\n",
    "    save_dir += f\"_projd_sobVectLec_{diffuFen_sobol_vect_len}\"\n",
    "print(save_dir)\n",
    "makedirs(save_dir, exist_ok=True)\n",
    "diffuFen_models_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myT = (((2*20)+(14*20)+(155*20))*4)/(60*60)\n",
    "f\"{int(myT)}hr, {(myT-int(myT))*60:.0f}min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for interval_domain in interval_domain_list:\n",
    "    save_name = f'1d_diffusion_{list(np.round(interval_domain,2))}_Nset_{N_set}'\n",
    "    save_name = save_name.replace(\"np.int64(\", \"\").replace(\"np.float64(\", \"\").replace(\")\", \"\").replace('.','_').replace(' ', '').replace('-','neg').replace('[','<').replace(']','>')\n",
    "    if not projectOutputToCG:\n",
    "        save_name += f'_h_{interval_mesh_resolution}_constraint_{indicator_constraint_val}'\n",
    "    else:\n",
    "        save_name += f'_sobVectLen_{diffuFen_sobol_vect_len}_h_{interval_mesh_resolution}_constraint_{indicator_constraint_val}'\n",
    "\n",
    "    t0 = time.time()\n",
    "    diffusion_1d = nm.model(model_type='diffusion_1D_both',\n",
    "                            P=P,\n",
    "                            mean=mu,\n",
    "                            std=std,\n",
    "                            meshInterval=interval_mesh_resolution,\n",
    "                            indicator_toggle=indicator_toggle,\n",
    "                            indicator_constraint_val=indicator_constraint_val,\n",
    "                            FEM_projection=projectOutputToCG,\n",
    "                            model_save_directory=save_dir,\n",
    "                            model_save_name=save_name)\n",
    "    t0_inner, t1_inner = 0, 0\n",
    "    t0_outer = time.time()\n",
    "    for curr_exp in range(expNum_set[0]):\n",
    "        if curr_exp != 0:\n",
    "            stdout.write(f'\\r{save_name} | time_prev_experiment_#{curr_exp}: {t1_inner-t0_inner:0.3f} (s). Time so far: {t1_inner-t0_outer:0.3f} (s)')\n",
    "            stdout.flush()\n",
    "        t0_inner = time.time()\n",
    "        solvers.run_sobols(model=diffusion_1d, N_set=N_set, x_interval_of_interest=interval_domain)\n",
    "        t1_inner = time.time()\n",
    "    diffuFen_models_list.append(diffusion_1d)\n",
    "    print('\\n')\n",
    "    diffusion_1d.save_my_model()\n",
    "    # save_model(model=diffusion_1d, save_dir=save_dir, save_name=save_name)\n",
    "    t1 = time.time()\n",
    "    print(f\" -> {interval_domain} done! Total time: {t1-t0:0.3f} (s).\\n---------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from utils.other_utils import load_model\n",
    "\n",
    "diffuFen_models_list = []\n",
    "file_sup_dir = 'data/1d_diffusion/pick_freeze/indicator/vector/h_1024_max_N_10000'\n",
    "files = glob(f\"{file_sup_dir}/*.pkl\")\n",
    "for file in files:\n",
    "    print(file)\n",
    "    diffuFen_models_list.append(load_model(load_dir=file))\n",
    "diffuFen_models_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plotter\n",
    "import re\n",
    "for file in files:\n",
    "    model = load_model(load_dir=file)\n",
    "# for model in diffuFen_models_list:\n",
    "    if 10000 not in model.N_set:\n",
    "        continue\n",
    "    file_name = file[len(file_sup_dir)+1:-4]\n",
    "    print(file_name)\n",
    "    plotter.plot(model=model,\n",
    "                N_set=model.N_set,\n",
    "                only_singulars=True,\n",
    "                withOutliers=False,\n",
    "                withTrend=False,\n",
    "                grid_toggle=True,\n",
    "                base_fontsize=22,\n",
    "                save_fig=True,\n",
    "                save_directory='figs/1d_diffusion/vbsa/traced',\n",
    "                fig_name=file_name)\n",
    "                # save_directory='figs/toy_2/pick_freeze/traced',\n",
    "                # fig_name=f'toy_2_convergence_{save_name}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\text{Affine Linear Function}\\;g_1$\n",
    "## Vectorized-Set-Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import numeric_models as nm\n",
    "from utils import solvers\n",
    "from utils.other_utils import save_model\n",
    "import time\n",
    "import numpy as np\n",
    "from os import makedirs, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_flag = True\n",
    "indicator_constraint_val = 3.75\n",
    "x_interval_domain = [0.25, 0.75]\n",
    "x_interval_mesh_resolution = 128\n",
    "\n",
    "expNum_set = [20]\n",
    "N_set = [100, 1000, 10000]\n",
    "# N_set = [10000]\n",
    "N_min = np.min(N_set)\n",
    "N_max = np.max(N_set)\n",
    "if indicator_flag:\n",
    "    save_dir = 'data/g_1/pick_freeze/indicator'\n",
    "else:\n",
    "    save_dir = 'data/g_1/pick_freeze/non_indicator'\n",
    "makedirs(save_dir, exist_ok=True)\n",
    "save_name = f\"toy_1_model_file__exprimentNum_{expNum_set[0]}__Nset_{N_set}__xInterval_{x_interval_domain}__h_{x_interval_mesh_resolution}\".replace(\"[\", \"\").replace(\"]\",'').replace(',', '_').replace(' ', '').replace('-','neg')\n",
    "if indicator_flag:\n",
    "    save_name += f\"__constraintVal_{indicator_constraint_val}\".replace('.', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_1_models_list = []\n",
    "t0 = time.time()\n",
    "toy_1_vect = nm.model(model_type='toy_1_vect', vectSize=3)\n",
    "toy_1_vect.indicator = indicator_flag\n",
    "toy_1_vect.constraintVal = indicator_constraint_val\n",
    "toy_1_vect.meshInterval = x_interval_mesh_resolution\n",
    "toy_1_vect.set_uniform_1D_mesh(interval=x_interval_domain)\n",
    "\n",
    "for _ in range(expNum_set[0]):\n",
    "    solvers.run_sobols(model=toy_1_vect, N_set=N_set)\n",
    "toy_1_models_list.append(toy_1_vect)\n",
    "\n",
    "save_model(model=toy_1_vect, save_dir=save_dir, save_name=save_name)\n",
    "t1 = time.time()\n",
    "print(f\"Done | T: {t1-t0:0.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from utils.other_utils import load_model\n",
    "toy_1_models_list = []\n",
    "files = glob(\"data/g_1/pick_freeze/**/*.pkl\")\n",
    "for file in files:\n",
    "    print(file)\n",
    "    toy_1_models_list.append(load_model(load_dir=file))\n",
    "toy_1_models_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plotter\n",
    "for model in toy_1_models_list:\n",
    "    plotter.plot(model=model,\n",
    "                multi_experiment=True,\n",
    "                withOutliers=False,\n",
    "                withTrend=True,\n",
    "                no_title=True,\n",
    "                not_differences=True,\n",
    "                only_singulars=True,\n",
    "                base_fontsize=20,\n",
    "                save_fig=True,\n",
    "                only_aggr=True,\n",
    "                toy_1_or_2=True,\n",
    "                grid_toggle=True,\n",
    "                save_directory='figs/g_1/pick_freeze/traced',\n",
    "                fig_name=f'g_1_convergence_{save_name}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\text{Affine Linear Function}\\;g_2$ \n",
    "## Vectorized-Set-Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import numeric_models as nm\n",
    "from utils import plotter, solvers\n",
    "from utils.other_utils import gen_uniform_1d_mesh_from_interval_and_resolution as genUniMesh\n",
    "from utils.other_utils import load_model, save_model, getSingletonIndexAsInt\n",
    "from glob import glob\n",
    "import time\n",
    "import numpy as np\n",
    "from os import makedirs, path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_flag = True\n",
    "indicator_constraint_val = 5.25\n",
    "x_interval_domain = [0.25, 0.75]\n",
    "x_interval_mesh_resolution = 128\n",
    "\n",
    "expNum_set = [20]\n",
    "N_set = [100, 1000, 10000]\n",
    "# N_set = [10000]\n",
    "N_min = np.min(N_set)\n",
    "N_max = np.max(N_set)\n",
    "if indicator_flag:\n",
    "    save_dir = 'data/g_2/pick_freeze/indicator'\n",
    "else:\n",
    "    save_dir = 'data/g_2/pick_freeze/non_indicator'\n",
    "makedirs(save_dir, exist_ok=True)\n",
    "save_name = f\"g_2_model_file__exprimentNum_{expNum_set[0]}__Nset_{N_set}__xInterval_{x_interval_domain}__h_{x_interval_mesh_resolution}\".replace(\"[\", \"\").replace(\"]\",'').replace(',', '_').replace(' ', '').replace('-','neg')\n",
    "if indicator_flag:\n",
    "    save_name += f\"__constraintVal_{indicator_constraint_val}\".replace('.', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_2_models_list = []\n",
    "t0 = time.time()\n",
    "toy_2_vect = nm.model(model_type='toy_2_vect', vectSize=3)\n",
    "toy_2_vect.indicator = indicator_flag\n",
    "toy_2_vect.constraintVal = indicator_constraint_val\n",
    "toy_2_vect.meshInterval = x_interval_mesh_resolution\n",
    "toy_2_vect.set_uniform_1D_mesh(interval=x_interval_domain)\n",
    "\n",
    "for _ in range(expNum_set[0]):\n",
    "    solvers.run_sobols(model=toy_2_vect, N_set=N_set)\n",
    "toy_2_models_list.append(toy_2_vect)\n",
    "save_model(model=toy_2_vect, save_dir=save_dir, save_name=save_name)\n",
    "t1 = time.time()\n",
    "print(f\"Done | T: {t1-t0:0.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_2_models_list = []\n",
    "files = glob(\"data/g_2/pick_freeze/**/*.pkl\")\n",
    "for file in files:\n",
    "    print(file)\n",
    "    toy_2_models_list.append(load_model(load_dir=file))\n",
    "toy_2_models_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in toy_2_models_list:\n",
    "    plotter.plot(model=model,\n",
    "                multi_experiment=True,\n",
    "                withOutliers=False,\n",
    "                withTrend=True,\n",
    "                no_title=True,\n",
    "                not_differences=True,\n",
    "                only_singulars=True,\n",
    "                base_fontsize=20,\n",
    "                save_fig=True,\n",
    "                only_aggr=True,\n",
    "                toy_1_or_2=True,\n",
    "                grid_toggle=True,\n",
    "                save_directory='figs/g_2/pick_freeze/traced',\n",
    "                fig_name=f'g_2_convergence_{save_name}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\text{Nonlinear Problem}\\;g_3$\n",
    "## Vectorized-Set-Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\;\\mathbf{y} = (\\mathbb{1}_{\\{y_1\\leq 0\\}},...,\\mathbb{1}_{\\{y_{h+1}\\leq 0\\}})^T$,\n",
    "### $y_i=G(X,U)=u_1+u_1u_2+x^{(i)}_hu_1$, \n",
    "### $\\quad u_i\\sim \\mathbb{U}[ -1,1],\\; i\\in\\{1,2\\}$, \n",
    "### $\\quad x\\in[ -1,1] \\rightarrow x_h\\in\\{-1,-1+\\frac{1-(-1)}{h},...,1\\}\\;\\;h\\in\\mathbb{N}_{>0}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import numeric_models as nm\n",
    "from utils import plotter, solvers\n",
    "from utils.other_utils import load_model, save_model\n",
    "from glob import glob\n",
    "import time\n",
    "import numpy as np\n",
    "from os import makedirs, path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating aggr' sobols via trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interval_domain = [-np.pi, -2.0]\n",
    "# interval_mesh_resolution = 8\n",
    "# ishigami_indicator_constraint_val = 3\n",
    "indicator_flag = True\n",
    "indicator_constraint_val = 0.0\n",
    "x_interval_domain = [-1.0, 1.0]\n",
    "x_interval_mesh_resolution = 128\n",
    "\n",
    "expNum_set = [20]\n",
    "N_set = [100, 1000, 10000]\n",
    "# N_set = [10000]\n",
    "N_min = np.min(N_set)\n",
    "N_max = np.max(N_set)\n",
    "if indicator_flag:\n",
    "    save_dir = 'data/g_3/pick_freeze/indicator'\n",
    "else:\n",
    "    save_dir = 'data/g_3/pick_freeze/non_indicator'\n",
    "# save_dir += f'{list(np.round(interval_domain,2))}'.replace(\"np.float64(\", \"\").replace(\")\", \"\").replace('.','_').replace(' ', '').replace('-','neg').replace('[','<').replace(']','>')\n",
    "# save_dir += f'_h_{interval_mesh_resolution}_constraint_{ishigami_indicator_constraint_val}'\n",
    "makedirs(save_dir, exist_ok=True)\n",
    "toy_model_vect_models_list = []\n",
    "save_name = f\"g_3_model_file__exprimentNum_{expNum_set[0]}__Nset_{N_set}__xInterval_{x_interval_domain}__h_{x_interval_mesh_resolution}\".replace(\"[\", \"\").replace(\"]\",'').replace(',', '_').replace(' ', '').replace('-','neg')\n",
    "if indicator_flag:\n",
    "    save_name += f\"__constraintVal_{indicator_constraint_val}\".replace('.', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "toy_model_vect = nm.model(model_type='toy_model_vect', vectSize=2)\n",
    "toy_model_vect.indicator = indicator_flag\n",
    "toy_model_vect.constraintVal = indicator_constraint_val\n",
    "toy_model_vect.meshInterval = x_interval_mesh_resolution\n",
    "toy_model_vect.set_uniform_1D_mesh(interval=x_interval_domain)\n",
    "\n",
    "for _ in range(expNum_set[0]):\n",
    "    solvers.run_sobols(model=toy_model_vect, N_set=N_set)\n",
    "toy_model_vect_models_list.append(toy_model_vect)\n",
    "\n",
    "\n",
    "save_model(model=toy_model_vect, save_dir=save_dir, save_name=save_name)\n",
    "t1 = time.time()\n",
    "print(f\"Done | T: {t1-t0:0.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_model_vect_models_list = []\n",
    "files = glob(\"data/g_3/pick_freeze/**/*.pkl\")\n",
    "for file in files:\n",
    "    print(file)\n",
    "    toy_model_vect_models_list.append(load_model(load_dir=file))\n",
    "toy_model_vect_models_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, file_dir in zip(toy_model_vect_models_list, files):\n",
    "    fig_name = path.basename(file_dir).replace('.dill','.pdf')\n",
    "    fig_name = path.basename(file_dir).replace('.pkl','.pdf')\n",
    "    save_dir = path.dirname(file_dir)\n",
    "    model.specifyX3 = True\n",
    "    model.x_3 = 0\n",
    "    print(fig_name)\n",
    "    plotter.plot(model=model,\n",
    "                multi_experiment=True,\n",
    "                withOutliers=False,\n",
    "                withTrend=True,\n",
    "                no_title=True,\n",
    "                not_differences=True,\n",
    "                only_singulars=True,\n",
    "                base_fontsize=20,\n",
    "                save_fig=True,\n",
    "                only_aggr=True,\n",
    "                toy_1_or_2=False,\n",
    "                grid_toggle=True,\n",
    "                save_directory='figs/g_3/pick_freeze/traced',\n",
    "                fig_name=f'g_3_convergence_{save_name}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envMLRG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
